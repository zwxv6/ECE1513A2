{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bL0awqcfZY7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7mhkeFifagW"
      },
      "outputs": [],
      "source": [
        "def fit_NeuralNetwork(X_train,y_train,alpha,hidden_layer_sizes,epochs):\n",
        "    #Enter implementation here\n",
        "    d = hidden_layer_sizes[0]\n",
        "    X_train = np.hstack([np.ones((X_train.shape[0], 1)), X_train])\n",
        "    N = X_train.shape[0]\n",
        "\n",
        "    # set weight of all layers\n",
        "    wAll = [] # use to store weights of all layer\n",
        "    w1 = []\n",
        "    # according input to set first layer weights\n",
        "    for d in range(0,d):\n",
        "      w1temp = np.random.normal(0, 0.1)\n",
        "      w1.append(w1temp)\n",
        "\n",
        "    weight1 = [] # store all weights of input layer to hidden layer\n",
        "    for a in range(0,X_train.shape[1]):\n",
        "      weight1.append(w1)\n",
        "\n",
        "    wAll.append(weight1)\n",
        "    # according hiddern layer size to set hiddern layer and output layer weights\n",
        "    for g in range(len(hidden_layer_sizes)-1):\n",
        "      w = []\n",
        "      for e in range(0,hidden_layer_sizes[g+1]):\n",
        "        wtemp = np.random.normal(0, 0.1)\n",
        "        w.append(wtemp)\n",
        "\n",
        "      weight = [] # store all weights of each hidden layer\n",
        "      for b in range(0,hidden_layer_sizes[g]+1):\n",
        "        weight.append(w)\n",
        "\n",
        "      wAll.append(weight)\n",
        "\n",
        "    wLast = [] # store all weights of hidden layer to output layer\n",
        "    for f in range(0,hidden_layer_sizes[len(hidden_layer_sizes)-1]+1):\n",
        "      wLasttemp = np.random.normal(0, 0.1)\n",
        "      wLast.append(wLasttemp)\n",
        "\n",
        "    wAll.append(wLast)\n",
        "\n",
        "    errAll = []\n",
        "\n",
        "    for i in range(epochs):\n",
        "      errAverge = 0\n",
        "      choiceArray=np.arange(0, N)\n",
        "      np.random.shuffle(choiceArray)\n",
        "      for n in range(0, N):\n",
        "        index=choiceArray[n]\n",
        "        x=np.transpose(X_train[index])\n",
        "        X = []\n",
        "        S = []\n",
        "        g = []\n",
        "        X,S = forwardPropagation(x,wAll) # run forward propagation to get X and S\n",
        "        g = backPropagation(X,y_train[index],S,wAll) # using X and S got from forward propagation to compute g by back propagation\n",
        "        wAll = updateWeights(wAll,g,alpha) # update weights by using g which got from back propagation\n",
        "        xlt = X[len(X)-1] # X_L\n",
        "        errAverge = errAverge + errorPerSample(xlt,y_train[index])\n",
        "\n",
        "      errAverge = errAverge/X_train.shape[0]\n",
        "      errAll.append(errAverge)\n",
        "\n",
        "    return errAll,wAll\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2L9-rwcnfbvn"
      },
      "outputs": [],
      "source": [
        "def forwardPropagation(x, weights):\n",
        "    #Enter implementation here\n",
        "    S = [] # store all s during the forward propagation\n",
        "    X = [] # store all x during the forward propagation\n",
        "    X.append(x)\n",
        "    wLast = weights[len(weights)-1] # get the weights from hiddern layer to output layer\n",
        "    xL = 0\n",
        "\n",
        "    xCurrent = []\n",
        "    xCurrent = x # x of current layer\n",
        "    # compute s and x of each layer\n",
        "    for g in range(len(weights)-1):\n",
        "      wCurrent = weights[g] # get the weights from current layer to next layer\n",
        "      sList = [] # store s which output from dot product\n",
        "      for i in range(len(wCurrent[0])):\n",
        "        temps = 0\n",
        "        for a in range(len(xCurrent)): # sum of x multiply weights to get s\n",
        "          wtemp = []\n",
        "          wtemp = wCurrent[a]\n",
        "          temps = temps + wtemp[i]*xCurrent[a]\n",
        "        sList.append(temps)\n",
        "      S.append(sList)\n",
        "\n",
        "      xList = [] # store x which output from activation function\n",
        "      for j in range(len(sList)): # using of s for activation function to get x of next layer\n",
        "        tempx = activation(sList[j])\n",
        "        xList.append(tempx)\n",
        "      xCurrent = xList\n",
        "      X.append(xCurrent)\n",
        "\n",
        "      xCurrent.insert(0,1) # add augmented vector for x of hidden layer\n",
        "\n",
        "    # compute s and output X_L\n",
        "    sLast = np.dot(xCurrent,wLast)\n",
        "    xL = outputf(sLast)\n",
        "    S.append(sLast)\n",
        "    X.append(xL)\n",
        "\n",
        "    return X,S\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2KbIOc5fdEI"
      },
      "outputs": [],
      "source": [
        "def errorPerSample(X,y_n):\n",
        "    #Enter implementation here\n",
        "    err = 0\n",
        "    err = errorf(X,y_n)\n",
        "\n",
        "    return err\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "woZrS2W5feHU"
      },
      "outputs": [],
      "source": [
        "def backPropagation(X,y_n,s,weights):\n",
        "    #Enter implementation here\n",
        "    sLast = s[len(s)-1]\n",
        "    sBeforeLast = s[len(s)-2]\n",
        "    xL = X[len(X)-1] #X_L\n",
        "    xBeforeLast = X[len(X)-2] # x before the output layer\n",
        "    wLast = weights[len(weights)-1] # get the weights from hiddern layer to output layer\n",
        "    dsBeforeLast = 0 # de/ds of x before the output layer\n",
        "    deltaBeforeLast = [] # backward message of the layer before the output layer\n",
        "    deltaAll = [] # store backward message of all layers\n",
        "    gBeforeLast = []\n",
        "    gfinal = []\n",
        "\n",
        "    # compute backward message of last layer\n",
        "    deltaLast = derivativeError(xL,y_n)*derivativeOutput(sLast)\n",
        "\n",
        "    # individually compute backward message of the layer before the last layer\n",
        "    # since this layer has different calcultion method for s with other layers\n",
        "    for a in range(len(sBeforeLast)):\n",
        "      dedxBeforeLast = deltaLast*wLast[a] # dedx\n",
        "      dsBeforeLast = derivativeActivation(sBeforeLast[a]) # deds\n",
        "      tempdeltaBeforeLast = dedxBeforeLast*dsBeforeLast # dedx*deds\n",
        "      deltaBeforeLast.append(tempdeltaBeforeLast)\n",
        "\n",
        "    # compute backward message of hidden layers\n",
        "    currentDelta = []\n",
        "    currentDelta = deltaBeforeLast\n",
        "    for g in range(len(weights)-2):\n",
        "      deltaList = []\n",
        "      sCurrent = []\n",
        "      wCurrent = []\n",
        "      sCurrent = s[len(weights)-2-1-g]\n",
        "      wCurrent = weights[len(weights)-2-1-g+1]\n",
        "      for b in range(len(sCurrent)):\n",
        "        dsCurrent = derivativeActivation(sCurrent[b]) # deds\n",
        "        dedx1 = 0\n",
        "        wtemp = wCurrent[b]\n",
        "        dedx = np.dot(wtemp, currentDelta) # dedx\n",
        "        tempdelta = dedx*dsCurrent # dedx*deds\n",
        "        deltaList.append(tempdelta)\n",
        "      currentDelta = deltaList\n",
        "      deltaAll.append(currentDelta)\n",
        "\n",
        "    # compute dedw of each weights of each layer\n",
        "    dwLast = []\n",
        "    for e in range(len(xBeforeLast)): # for last layer\n",
        "      tempdwLast = deltaLast*xBeforeLast[e] # backward messgae mulitply x\n",
        "      dwLast.append(tempdwLast)\n",
        "    gfinal.append(dwLast)\n",
        "\n",
        "    xForThisLayer = X[len(X)-3]\n",
        "    for d in range(len(xForThisLayer)):\n",
        "      dwBeforeLast = []\n",
        "      for e in range(len(deltaBeforeLast)): # for the layer before the last layer\n",
        "        tempdwBeforeLast = deltaBeforeLast[e]*xForThisLayer[d] # backward messgae mulitply x\n",
        "        dwBeforeLast.append(tempdwBeforeLast)\n",
        "      gBeforeLast.append(dwBeforeLast)\n",
        "    gfinal.append(gBeforeLast)\n",
        "\n",
        "    for c in range(len(deltaAll)):\n",
        "      gList = []\n",
        "      xCurrent = []\n",
        "      detlaCurrent = []\n",
        "      xCurrent = X[len(deltaAll)-1-c]\n",
        "      detlaCurrent = deltaAll[len(deltaAll)-1-c]\n",
        "      for f in range(len(xCurrent)): # for the general hiddern layers\n",
        "        dw = []\n",
        "        for g in range(len(detlaCurrent)):\n",
        "          tempdw = detlaCurrent[g]*xCurrent[f] # backward messgae mulitply x\n",
        "          dw.append(tempdw)\n",
        "        gList.append(dw)\n",
        "      gfinal.append(gList)\n",
        "\n",
        "    return gfinal\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7kYNdfUffqF"
      },
      "outputs": [],
      "source": [
        "def updateWeights(weights,g,alpha):\n",
        "    #Enter implementation here\n",
        "    nW = [] # store new weights of all layers\n",
        "\n",
        "    for f in range(len(weights)):\n",
        "      wCurrent = weights[f] # get weights of each layers\n",
        "      gCurent = np.asarray(g[len(weights)-1-f]) # get g of each weights\n",
        "      for i in range(len(wCurrent)):\n",
        "        wCurrent[i] = wCurrent[i] - alpha * gCurent[i] # wi = wi - alpha*gi\n",
        "      nW.append(wCurrent)\n",
        "\n",
        "    return nW\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CrYKYNTYfh2z"
      },
      "outputs": [],
      "source": [
        "def activation(s):\n",
        "  #Enter implementation here\n",
        "    output = 0\n",
        "    if s > 0: # ReLu function\n",
        "        output = s\n",
        "    else:\n",
        "        output = 0\n",
        "\n",
        "    return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CF9xix5cfjXF"
      },
      "outputs": [],
      "source": [
        "def derivativeActivation(s):\n",
        "    #Enter implementation here\n",
        "    output = 0\n",
        "    if s > 0:\n",
        "        output = 1\n",
        "    else:\n",
        "        output = 0\n",
        "\n",
        "    return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSYPuDEafkZl"
      },
      "outputs": [],
      "source": [
        "def outputf(s):\n",
        "    #Enter implementation here\n",
        "    x_L = 0\n",
        "    x_L = 1/(1+np.exp(-s))\n",
        "\n",
        "    return x_L\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9h4FKtZfleS"
      },
      "outputs": [],
      "source": [
        "def derivativeOutput(s):\n",
        "    #Enter implementation here\n",
        "    x_L = 0\n",
        "    x_L = np.exp(-s)/pow(1+np.exp(-s),2)\n",
        "\n",
        "    return x_L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ev21c0nKfmwm"
      },
      "outputs": [],
      "source": [
        "def errorf(x_L,y):\n",
        "    #Enter implementation here\n",
        "    en = 0\n",
        "\n",
        "    if y == 1:\n",
        "        en = -np.log(x_L)\n",
        "    elif y == -1:\n",
        "        en = -np.log(1-x_L)\n",
        "\n",
        "    return en\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFYVkUZFfn58"
      },
      "outputs": [],
      "source": [
        "def derivativeError(x_L,y):\n",
        "    #Enter implementation here\n",
        "    dedx = 0\n",
        "    if y == 1:\n",
        "        dedx = -1/x_L\n",
        "    elif y == -1:\n",
        "        dedx = 1/(1-x_L)\n",
        "\n",
        "    return dedx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-Uc3MEgfo-n"
      },
      "outputs": [],
      "source": [
        "def pred(x_n,weights):\n",
        "    #Enter implementation here\n",
        "    c = []\n",
        "    for a in range(x_n.shape[0]):\n",
        "      X,S = forwardPropagation(x_n[a], weights) # run forward propagation to get X\n",
        "      yHat = 0\n",
        "      X_L = X[len(X)-1]\n",
        "      if X_L < 0.5:\n",
        "        yHat = -1\n",
        "      else:\n",
        "        yHat = 1\n",
        "      c.append(yHat)\n",
        "\n",
        "    return c\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Q7Uu52jfqnz"
      },
      "outputs": [],
      "source": [
        "def confMatrix(X_train,y_train,w):\n",
        "    #Enter implementation here\n",
        "    m = np.ones((2,2))\n",
        "    TrueNegative = 0\n",
        "    FalsePositive = 0\n",
        "    FalseNegative = 0\n",
        "    TruePositive = 0\n",
        "\n",
        "    X_train = np.hstack([np.ones((X_train.shape[0], 1)), X_train])\n",
        "    c = pred(X_train,w)\n",
        "    for i in range(y_train.shape[0]):\n",
        "      if c[i] == -1:\n",
        "        if y_train[i] == -1:\n",
        "          TrueNegative = TrueNegative + 1\n",
        "        elif y_train[i] == 1:\n",
        "          FalsePositive = FalsePositive + 1\n",
        "      elif c[i] == 1:\n",
        "        if y_train[i] == -1:\n",
        "          FalseNegative = FalseNegative + 1\n",
        "        elif y_train[i] == 1:\n",
        "          TruePositive = TruePositive + 1\n",
        "\n",
        "    m[0][0] = TrueNegative\n",
        "    m[0][1] = FalsePositive\n",
        "    m[1][0] = FalseNegative\n",
        "    m[1][1] = TruePositive\n",
        "\n",
        "    return m\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hhZQRfCfsE0"
      },
      "outputs": [],
      "source": [
        "def plotErr(e,epochs):\n",
        "    #Enter implementation here\n",
        "    x = list(range(1,epochs+1))\n",
        "    y = e\n",
        "\n",
        "    plt.plot(x,y)\n",
        "    plt.show\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIjycdBZftJN"
      },
      "outputs": [],
      "source": [
        "def test_SciKit(X_train, X_test, Y_train, Y_test):\n",
        "    #Enter implementation here\n",
        "    pct = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(30, 10), random_state=1)\n",
        "    pct.fit(X_train,Y_train)\n",
        "\n",
        "    pred_pct=pct.predict(X_test)\n",
        "    print ('Test accuracy: ', pct.score(X_test, Y_test))\n",
        "\n",
        "    m = confusion_matrix(Y_test,pred_pct)\n",
        "\n",
        "    pred_pct=pct.predict(X_train)\n",
        "    print ('Train accuracy: ',pct.score(X_train, Y_train))\n",
        "\n",
        "\n",
        "    return m\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "jSsRHVCdfuvG",
        "outputId": "95e734c4-9baa-478d-d4ad-80ad13c70c56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy:  0.9\n",
            "Train accuracy:  0.9625\n",
            "Confusion Matrix is from Part 1a is:  [[ 6.  1.]\n",
            " [ 2. 11.]]\n",
            "Confusion Matrix from Part 1b is: [[ 7  1]\n",
            " [ 1 11]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "def test_Part1():\n",
        "    from sklearn.datasets import load_iris\n",
        "    X_train, y_train = load_iris(return_X_y=True)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_train[50:],y_train[50:],test_size=0.2, random_state=1)\n",
        "\n",
        "    for i in range(80):\n",
        "        if y_train[i]==1:\n",
        "            y_train[i]=-1\n",
        "        else:\n",
        "            y_train[i]=1\n",
        "    for j in range(20):\n",
        "        if y_test[j]==1:\n",
        "            y_test[j]=-1\n",
        "        else:\n",
        "            y_test[j]=1\n",
        "\n",
        "    err,w=fit_NeuralNetwork(X_train,y_train,1e-2,[30, 10],100)\n",
        "\n",
        "    plotErr(err,100)\n",
        "\n",
        "    cM=confMatrix(X_test,y_test,w)\n",
        "\n",
        "    sciKit=test_SciKit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "    print(\"Confusion Matrix is from Part 1a is: \",cM)\n",
        "    print(\"Confusion Matrix from Part 1b is:\",sciKit)\n",
        "\n",
        "test_Part1()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}